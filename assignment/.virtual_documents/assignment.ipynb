








import pandas as pd

airbnb = pd.read_csv("/Users/vaibhavjha/wrangling/assignment/data/airbnb_hw.csv")

airbnb['Price'] = airbnb['Price'].str.replace(',', '') # REPLACE commas with nothing
print(airbnb['Price'].unique()) # Gives a list of all the unique values

airbnb['Price'] = pd.to_numeric(airbnb['Price'], errors='coerce') # COERCE column to numeric
print(airbnb['Price'])

airbnb['Price'].isnull().sum() # 0 missing values


import pandas as pd
import numpy as np

sharks = pd.read_csv("/Users/vaibhavjha/wrangling/assignment/data/sharks.csv", low_memory = False)
print(sharks.head(10))
sharks['Type'].unique()
sharks['Type'].isnull().sum()

# Missing data on 4087: no data in any column
print(sharks[sharks['Type'].isnull()])
sharks['Reason Missing'] = None
sharks.loc[4087,'Reason Missing'] = 'No data whatsoever on person'
print(sharks.loc[4087,:])

# Missing data on 239, 537 (unreported)
sharks.loc[(239, 537),'Reason Missing'] = 'Unreported'
print(sharks.loc[(239,537),:])

# Missing data on 5025, 5864 (reported)
sharks.loc[(5025, 5864),'Reason Missing'] = 'Reported'
print(sharks.loc[(5025,5864),:])


# Stratified the 'Type' missing observations as: No data whatsoever, unreported, and reported


print(sharks['Type'].value_counts()) # Gives different types and frequencies

type = sharks['Type']
type = type.replace(['Sea Disaster', 'Watercraft', 'Boat', 'Boating', 'Boatomg'], 'Water issues') # Grouped together all known water issues
type.value_counts()

type = type.replace(['Invalid', 'Questionable', 'Unconfirmed', 'Unverified', 'Under investigation'], np.nan) # Removed all values associated with these types
type.value_counts()

sharks['Type'] = type # Replace the column in the sharks df
sharks['Type'].value_counts() # Complete, cleaned categorical variable


import pandas as pd
import numpy as np

crime = pd.read_parquet("/Users/vaibhavjha/wrangling/assignment/data/justice_data.parquet")
crime.head(10)

print(crime['WhetherDefendantWasReleasedPretrial'])
crime = crime.rename(columns = {'WhetherDefendantWasReleasedPretrial':'Pretrial'}) # Shortened column name

crime['Pretrial'].unique()
crime['Pretrial'].head(10)
crime['Pretrial'].value_counts()

# It seems the parquet file codes the variables in 0 and 1, and that 9's are missing values.
# Want to recode 9's as np.nan's

crime['Pretrial'] = crime['Pretrial'].replace([9], np.nan) # Notice the list
print(crime['Pretrial'])
print(crime['Pretrial'].value_counts()) 

# Now have 1s and 0s, with missing values as np.nan


crime = crime.rename(columns = {'ImposedSentenceAllChargeInContactEvent':'Contact'})
crime['Contact'].unique()
crime['Contact'].value_counts()
# it seems the most popular value is a blank value
crime['Contact'] = pd.to_numeric(crime['Contact'], errors='coerce') # made the column go from string to numeric, doing so marked blanks as NaN
crime['Contact'] = crime['Contact'].round(0)
crime['Contact'].head(20)






